{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T21:33:06.201023Z",
     "start_time": "2025-03-20T21:33:05.211391Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    mean_squared_error\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:33:07.858075Z",
     "start_time": "2025-03-20T21:33:06.665877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\UCD\\Spring\\Data management and mining\\Group Assignment\\student_dataset.csv\")"
   ],
   "id": "3514ab3f36c286c9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:36:29.074433Z",
     "start_time": "2025-03-20T21:36:29.064319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------- Preprocessing Without Feature Engineering --------------------------------\n",
    "\n",
    "def preprocess_no_feature_engineering(df_raw):\n",
    "    \"\"\"Preprocess the data without additional feature engineering.\"\"\"\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Convert Transaction.Date to datetime\n",
    "    df[\"Transaction.Date\"] = pd.to_datetime(df[\"Transaction.Date\"], errors=\"coerce\")\n",
    "    df[\"Transaction_Day\"] = df[\"Transaction.Date\"].dt.day.fillna(df[\"Transaction.Date\"].dt.day.median())\n",
    "    df[\"Transaction_Month\"] = df[\"Transaction.Date\"].dt.month.fillna(df[\"Transaction.Date\"].dt.month.median())\n",
    "    df[\"Transaction_Year\"] = df[\"Transaction.Date\"].dt.year.fillna(df[\"Transaction.Date\"].dt.year.median())\n",
    "    df.drop(columns=[\"Transaction.Date\"], inplace=True)\n",
    "\n",
    "    # Handle missing values in numeric columns\n",
    "    numeric_columns = [\n",
    "        \"Transaction.Amount\",\n",
    "        \"Customer.Age\",\n",
    "        \"Account.Age.Days\",\n",
    "        \"Transaction.Hour\",\n",
    "        \"Quantity\",\n",
    "    ]\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "    # Encode Categorical Variables\n",
    "    categorical_columns = [\n",
    "        \"source\",\n",
    "        \"browser\",\n",
    "        \"Payment.Method\",\n",
    "        \"Product.Category\",\n",
    "        \"Device.Used\",\n",
    "    ]\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    if \"Is.Fraudulent\" in df.columns:\n",
    "        df[\"Is.Fraudulent\"] = df[\"Is.Fraudulent\"].astype(int)\n",
    "\n",
    "    return df"
   ],
   "id": "1a86bb77cb99b6d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:36:39.199390Z",
     "start_time": "2025-03-20T21:36:39.193263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------- Preprocessing With Feature Engineering --------------------------------\n",
    "\n",
    "def preprocess_with_feature_engineering(df_raw):\n",
    "    \"\"\"Preprocess the data with advanced feature engineering.\"\"\"\n",
    "    df = preprocess_no_feature_engineering(df_raw)  # Start with basic preprocessing\n",
    "\n",
    "    # Add Feature Engineering\n",
    "    df[\"Transaction_per_AccountAge\"] = df[\"Transaction.Amount\"] / (df[\"Account.Age.Days\"] + 1)\n",
    "    df[\"Transaction_per_Quantity\"] = df[\"Transaction.Amount\"] / (df[\"Quantity\"] + 1)\n",
    "    df[\"Total_Spending\"] = df[\"Transaction.Amount\"] * df[\"Quantity\"]\n",
    "\n",
    "    # Spending Speed\n",
    "    df[\"Spending_Speed\"] = df[\"Total_Spending\"] / (df[\"Account.Age.Days\"] + 1)\n",
    "\n",
    "    # High Amount Transaction Flag\n",
    "    threshold = np.percentile(df[\"Transaction.Amount\"], 75)\n",
    "    df[\"High_Amount_Transaction\"] = (df[\"Transaction.Amount\"] > threshold).astype(int)\n",
    "\n",
    "    return df\n"
   ],
   "id": "3936df156d04d8c8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:46:38.508462Z",
     "start_time": "2025-03-20T21:46:38.498587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------- Model Training & Evaluation Function --------------------------------\n",
    "\n",
    "def train_and_evaluate(X, y, description=\"Model\"):\n",
    "    \"\"\"Train and evaluate a Random Forest classifier.\"\"\"\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\n--- {description} ---\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Not Fraud\", \"Fraud\"],\n",
    "        yticklabels=[\"Not Fraud\", \"Fraud\"],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix - {description}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC Curve (area = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {description}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "a8c3da8788f37ae0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:47:52.402837Z",
     "start_time": "2025-03-20T21:47:52.394520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_no_feature_engineering(df_raw):\n",
    "    \"\"\"Preprocess the data without additional feature engineering.\"\"\"\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # Check if 'Transaction.Date' exists in the dataset\n",
    "    if \"Transaction.Date\" in df.columns:\n",
    "        # Convert Transaction.Date to datetime\n",
    "        df[\"Transaction.Date\"] = pd.to_datetime(df[\"Transaction.Date\"], errors=\"coerce\")\n",
    "        df[\"Transaction_Day\"] = df[\"Transaction.Date\"].dt.day.fillna(\n",
    "            df[\"Transaction.Date\"].dt.day.median()\n",
    "        )\n",
    "        df[\"Transaction_Month\"] = df[\"Transaction.Date\"].dt.month.fillna(\n",
    "            df[\"Transaction.Date\"].dt.month.median()\n",
    "        )\n",
    "        df[\"Transaction_Year\"] = df[\"Transaction.Date\"].dt.year.fillna(\n",
    "            df[\"Transaction.Date\"].dt.year.median()\n",
    "        )\n",
    "        df.drop(columns=[\"Transaction.Date\"], inplace=True)\n",
    "    else:\n",
    "        print(\"Warning: 'Transaction.Date' column is missing from the dataset!\")\n",
    "        # Optionally add temporary columns if needed\n",
    "        df[\"Transaction_Day\"] = np.nan\n",
    "        df[\"Transaction_Month\"] = np.nan\n",
    "        df[\"Transaction_Year\"] = np.nan\n",
    "\n",
    "    # Handle missing values in numeric columns\n",
    "    numeric_columns = [\n",
    "        \"Transaction.Amount\",\n",
    "        \"Customer.Age\",\n",
    "        \"Account.Age.Days\",\n",
    "        \"Transaction.Hour\",\n",
    "        \"Quantity\",\n",
    "    ]\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "    # Encode Categorical Variables\n",
    "    categorical_columns = [\n",
    "        \"source\",\n",
    "        \"browser\",\n",
    "        \"Payment.Method\",\n",
    "        \"Product.Category\",\n",
    "        \"Device.Used\",\n",
    "    ]\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Convert Is.Fraudulent column to integer if it exists\n",
    "    if \"Is.Fraudulent\" in df.columns:\n",
    "        df[\"Is.Fraudulent\"] = df[\"Is.Fraudulent\"].astype(int)\n",
    "\n",
    "    return df\n"
   ],
   "id": "bf98750805b77d44",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af4587a8de72119d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
